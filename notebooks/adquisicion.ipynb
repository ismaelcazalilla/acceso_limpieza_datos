{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b44a8c9",
   "metadata": {},
   "source": [
    "# Adquisición de datos para finanzas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d59549e",
   "metadata": {},
   "source": [
    "## 1. Adquisición de datos a partir de ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3923fe5",
   "metadata": {},
   "source": [
    "### 1.1 Ficheros separados por coma (CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de paquetes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fa3a2",
   "metadata": {},
   "source": [
    "Utilizaremos diferentes métodos de Pandas para leer los distintos tipos de ficheros. Para CSV se emplea ```read_csv()```. Si no se especifica usa el separador por defecto **\",\"**.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49adec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_df = pd.read_csv('../data/ecommerce.csv')\n",
    "invoices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff853742",
   "metadata": {},
   "source": [
    "Cuando el separador no es **\",\"** hay que definirlo explícitamente. Puede ser **';'**, tabulación, **'/'** u otros.\n",
    "\n",
    "En caso contrario no leerá correctamente los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91347d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_semicolon_sep_df = pd.read_csv('../data/ecommerce_semicolon_sep.csv')\n",
    "invoices_semicolon_sep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265db9a",
   "metadata": {},
   "source": [
    "La forma de especificar el separador es con el parámetro ```sep```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_semicolon_sep_df = pd.read_csv('../data/ecommerce_semicolon_sep.csv', sep=';')\n",
    "invoices_semicolon_sep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f23c966",
   "metadata": {},
   "source": [
    "### 1.2. Ficheros de Excel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46056dc2",
   "metadata": {},
   "source": [
    "En el caso de los ficheros xlsx se utiliza el método ```read_excel()```. Es necesario especificar la hoja de la que vamos a extraer los datos.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_df = pd.read_excel('../data/ecommerce_excel.xlsx', sheet_name=\"2024\")\n",
    "invoices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e603db",
   "metadata": {},
   "source": [
    "### 1.3. Ficheros JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16cb23",
   "metadata": {},
   "source": [
    "Para los ficheros JSON utilizaremos ```read_json()```. Más adelante, en el apartado de API veremos algunas particularidades de la lectura de esta forma de estructurar los datos.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_json.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdba3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_json_df = pd.read_json('../data/ecommerce.json')\n",
    "ecommerce_json_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10ab1d",
   "metadata": {},
   "source": [
    "### 1.4. Ficheros en formato parquet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399754e",
   "metadata": {},
   "source": [
    "Los ficheros de [Apache Parquet](https://parquet.apache.org/) tienen el inconveniente de no ser legibles por un ser humano, debido a la forma en que estructura los datos y metadatos.\n",
    "\n",
    "Es necesario instalar y especificar el motor de serialización. Los más frecuentes son [Apache Arrow](https://arrow.apache.org/) y [Fast Parquet](https://fastparquet.readthedocs.io/en/latest/). Lo concretamos con el parámetro ```engine```.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae243f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_parquet_df = pd.read_parquet('../data/ecommerce.parquet', engine='pyarrow')\n",
    "ecommerce_parquet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d8bd7",
   "metadata": {},
   "source": [
    "## 2. Adquisición de datos a través de APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de paquetes\n",
    "import requests\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18bff1",
   "metadata": {},
   "source": [
    "Necesitamos importar la librería **requests**, que nos permitirá realizar peticiones a la API.\n",
    "\n",
    "En este caso el método que necesitaremos para extraer los datos es ```get()```. En las peticiones necesitamos especificar varios parámetros:\n",
    "* **url**: dirección web a la que apunta la petición.\n",
    "* **headers**: configuración de cabeceras para la petición.\n",
    "* **querystring**: parámetros que se añaden a la url.\n",
    "\n",
    "Si utilizáramos una petición de tipo ```post()``` necesitaríamos concretar un **body**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://real-time-product-search.p.rapidapi.com/search\"\n",
    "\n",
    "querystring = {\"q\":\"Nike shoes\",\"country\":\"us\",\"language\":\"en\",\"limit\":\"30\"}\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"be814bcabbmshc4f57ebcf4b7568p1eb15djsn52335224755f\",\n",
    "\t\"X-RapidAPI-Host\": \"real-time-product-search.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring).json()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c1bc5",
   "metadata": {},
   "source": [
    "De toda la respuesta solo necesitamos los datos, que se encuentran en el atributo **data** en este caso. Por lo tanto lo extraemos para procesarlo, teniendo en cuenta que es de tipo diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea99a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = response[\"data\"]\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b02e2d0",
   "metadata": {},
   "source": [
    "Para procesar los datos como Dataframe de Pandas se utilizará el constructor de la clase **Dataframe**. En este caso se pasa el diccionario como parámetro, y seleccionamos los atributos que queramos procesar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = [\n",
    "    'product_id',\n",
    "    'product_title',\n",
    "    'product_rating',\n",
    "    'typical_price_range',\n",
    "    'offer'\n",
    "]\n",
    "data_df = pd.DataFrame(data_dict)[selected_cols]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3078ec6f",
   "metadata": {},
   "source": [
    "Como vemos hay un problema en la columna **offer**. Al estar anidado un objeto en este atributo necesitamos aplanarla, generando columnas por cada uno de esos atributos. Para aplanarlo utilizamos ```json_normalize()``` con nuestra columna.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html\n",
    "\n",
    "Una vez aplanado, unimos las nuevas columnas con el dataframe original para tener el registro completo sin anidamientos. Para unir ambos dataframes utilizaremos ```concat()```.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.concat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanar el diccionario dentro de la columna 'datos'\n",
    "df_aplanado = json_normalize(data_df['offer'])\n",
    "\n",
    "# Concatenar el DataFrame aplanado con el DataFrame original\n",
    "df_resultante = pd.concat([data_df, df_aplanado], axis=1)\n",
    "\n",
    "cols_to_drop = [\n",
    "    'offer',\n",
    "    'offer_page_url',\n",
    "    'store_reviews_page_url',\n",
    "    'original_price',\n",
    "    'product_condition',\n",
    "    'buy_now_url',\n",
    "    'on_sale',\n",
    "    'shipping'\n",
    "]\n",
    "\n",
    "# Eliminamos columnas innecesarias\n",
    "df_resultante = df_resultante.drop(columns=cols_to_drop, axis=1)\n",
    "\n",
    "df_resultante.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50a768",
   "metadata": {},
   "source": [
    "## 3. Adquisición de datos procedentes de bases de datos relacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc4851",
   "metadata": {},
   "source": [
    "**Nota**: Se ha generado una BBDD PostgreSQL en https://console.neon.tech/app/projects de forma gratuita para este caso. Se han insertado 18 registros del CSV de ecommerce trabajado previamente para realizar pruebas.\n",
    "\n",
    "Para poder conectarnos con BBDD relacionales utilizaremos los paquetes ```postgresql``` y ```sqlalchemy```. Con ellos generaremos una conexión con nuestra BBDD, utilizando la configuración del objeto ***URL**.\n",
    "\n",
    "Con ```create_engine()``` generamos una conexión con nuestra BBDD relacional, de modo que sea posible realizar cosultas SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, URL\n",
    "\n",
    "url_object = URL.create(\n",
    "    \"postgresql\",\n",
    "    username=\"ismaelcazalilla\",\n",
    "    password=\"l10EaBKMzjJU\",\n",
    "    host=\"ep-throbbing-haze-36918596.eu-central-1.aws.neon.tech\",\n",
    "    database=\"adquisicion_datos\",\n",
    ")\n",
    "\n",
    "# Generamos una instancia de motor de conexión a la base de datos\n",
    "db_engine = create_engine(url_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f8088",
   "metadata": {},
   "source": [
    "Una vez establecida la conexión se utiliza el método ```read_sql()```, en el que escribiremos la sentencia SQL, así como el motor de BBDD.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html#pandas.read_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectamos con la base de datos y lanzamos una query para leer los datos\n",
    "with db_engine.connect() as conn, conn.begin():  \n",
    "    df = pd.read_sql(\"SELECT * FROM adquisicion.ecommerce WHERE invoiceno = '536365'\", con=db_engine)\n",
    "    \n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
